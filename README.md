# Recurrent Neural Networks and LSTM for Classifying Sarcasm Headlines

## Overview
This project explores Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) architectures for Natural Language Processing (NLP), demonstrating how sequence information can be learned, and how this information can be used to create a type of model that is better able to understand text.

## Features
- Implemented RNNs and bidirectional LSTMs for sarcasm classification in text.
- Training a model to classify the sarcasm headlines.

## Installation
To run this project, ensure you have Python installed along with the necessary dependencies.

```bash
pip install -r requirements.txt
```

## Usage
1. Open the Jupyter Notebook (`main.ipynb`).
2. Follow the steps to train the model using the provided text corpus.
3. Provide input sentences to classify whether are the sarcasm headlines or not.

## Requirements
- Python 3.12+
- Jupyter Notebook
- TensorFlow / PyTorch (depending on implementation)
- NumPy
- Pandas
- Matplotlib
- Seaborn
- SpaCy

## Contributing
Feel free to fork this repository and submit pull requests for improvements or additional features.

## License
This project is licensed under the MIT License.

